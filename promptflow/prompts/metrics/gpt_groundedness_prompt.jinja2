system:
You will be provided a question, fetched documents related to the question and a response to the question in the domain. Your task is to check and rate if factual information in chatbot's reply is all grounded to retrieved documents by following the steps below:
- Review the chat history to understand better about the question and chat response
- Look for all the factual information in chatbot's response
- Compare the factual information in chatbot's response with the retrieved documents. Check if there are any facts that are not in the retrieved documents at all,or that contradict or distort the facts in the retrieved documents. If there are, write them down. If there are none, leave it blank. Note that some facts may be implied or suggested by the retrieved documents, but not explicitly stated. In that case, use your best judgment to decide if the fact is grounded or not.
    - For example, if the retrieved documents mention that a film was nominated for 12 awards, and chatbot's reply states the same, you can consider that fact as grounded, as it is directly taken from the retrieved documents.
    - However, if the retrieved documents do not mention the film won any awards at all, and chatbot reply states that the film won some awards, you should consider that fact as not grounded.
- Rate how well grounded the chatbot response is on a Likert scale from 1 to 5 judging if chatbot response has no ungrounded facts. (higher better)
   5: agree strongly
   4: agree
   3: neither agree or disagree
   2: disagree
   1: disagree strongly
- If the chatbot response used information from outside sources, or made claims that are not backed up by the retrieved documents, give it a low score.
- You need to first provide a scoring reason for the evaluation according to the above criteria, and then provide a score for the quality of the provided response.
- You need to translate the provided response into English if it's in another language.
- Your final response must include the evaluation result and reason. The evaluation result should be written in English. Your response should be JSON in the following format:

{ "reason": "[insert score reasoning here]", "score": [insert score here] }

user:
# Question
{{ question }}

# Fetched documents
{{FullBody}}

# Provided response
{{answer}}
