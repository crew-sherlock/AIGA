$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Flow.schema.json
environment:
  python_requirements_txt: requirements.txt
additional_includes:
- ../../src/
- ../prompts/
inputs:
  deployment_name:
    type: string
    default: gpt-4o-2024-05-13
  chat_history:
    type: list
    default: []
    is_chat_history: true
  question:
    type: string
    default: what is BERT?
    is_chat_input: true
  api_version:
    type: string
    default: 2024-02-15-preview
outputs:
  answer:
    type: string
    reference: ${generate_response.output}
    is_chat_output: true
  groundedness_score:
    type: int
    reference: ${parse_groundedness.output}
    is_chat_output: false
nodes:
- name: rewrite_question
  type: prompt
  source:
    type: code
    path: prompts/rewrite_question_prompt.jinja2
  inputs:
    chat_history: ${inputs.chat_history}
    question: ${inputs.question}
- name: llm_call
  type: python
  source:
    type: code
    path: src/tools/llm/chat.py
  inputs:
    prompt: ${rewrite_question.output}
    deployment_name: ${inputs.deployment_name}
    api_version: ${inputs.api_version}
- name: generate_response
  type: prompt
  source:
    type: code
    path: generate_response_prompt.jinja2
  inputs:
    question: ${rewrite_question.output}
    chat_history: ${inputs.chat_history}
    content: ${llm_call.output}
- name: llm_call2
  type: python
  source:
    type: code
    path: src/tools/llm/chat.py
  inputs:
    prompt: ${generate_response.output}
    deployment_name: ${inputs.deployment_name}
    api_version: ${inputs.api_version}
- name: groundedness
  type: prompt
  source:
    type: code
    path: prompts/metrics/gpt_groundedness_prompt.jinja2
  inputs:
    question: ${llm_call2.output}
    context: ${llm_call.output}
    answer: ${llm_call.output}
- name: llm_call3
  type: python
  source:
    type: code
    path: src/tools/llm/chat.py
  inputs:
    prompt: ${groundedness.output}
    deployment_name: ${inputs.deployment_name}
    api_version: ${inputs.api_version}
- name: parse_groundedness
  type: python
  source:
    type: code
    path: src/tools/metrics/parse_llm_evaluation_score.py
  inputs:
    llm_evaluation_score: ${llm_call3.output}
