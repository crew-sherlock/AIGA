name: platform_ci_dev_workflow

on:
  workflow_call:
    inputs:
      env_name:
        type: string
        description: "Execution Environment"
        required: true
        default: "dev"
      use_case_base_path:
        type: string
        description: "The flow use-case to execute"
        required: true
        default: "web_classification"
      deployment_type:
        type: string
        description: "Determine type of deployment - aml, aks, docker, webapp"
        required: true
    secrets:
      azure_credentials:
        description: "service principal authentication to Azure"
        required: true
      registry_details:
        description: "prompt flow registry details"
        required: false
      aoai_api_key:
        description: "azure openai key"
        required: true
      aoai_api_base:
        description: "azure openai endpoint"
        required: true
      
jobs:
  flow-experiment-and_evaluation:
    name: prompt flow experiment and evaluation job
    runs-on: ubuntu-latest
    environment:
      name: ${{ inputs.env_name }}
    env:
      RESOURCE_GROUP_NAME: ${{ vars.RESOURCE_GROUP_NAME }}
      WORKSPACE_NAME: ${{ vars.WORKSPACE_NAME }}
      AZURE_SUBSCRIPTION_ID: ${{ vars.SUBSCRIPTION_ID }}
      AOAI_API_KEY: ${{ secrets.aoai_api_key }}
      AOAI_API_BASE: ${{ secrets.aoai_api_base }}
    
    steps:
      - name: Checkout Actions
        uses: actions/checkout@v4

      - name: Azure login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.azure_credentials }}

      - name: Configure Azure ML Agent
        uses: ./.github/actions/configure_azureml_agent
        with:
          versionSpec: "3.11"
          base_path: ${{ inputs.use_case_base_path }}

      #=====================================
      # Registers experiment dataset in Azure ML as Data Asset
      # Reads appropriate field values from experiment.yaml or experiment.<env>.yaml
      #=====================================      
      - name: Register experiment data asset
        uses: ./.github/actions/execute_script
        with:
          step_name: "Register experiment data asset"
          script_parameter: |
            python -m llmops.common.register_data_asset \
            --subscription_id ${{ env.AZURE_SUBSCRIPTION_ID }} \
            --base_path ${{ inputs.use_case_base_path }} \
            --env_name ${{ inputs.env_name }}

      #=====================================
      # Executes Standard flow for a scenario
      # Generates Reports for each RUN as well as consolidated one
      # Execute a RUN for each unique variant combination (keeping default variant id for other nodes)
      # Loads appropriate experiment data from Azure ML data asset
      # Reads appropriate field values from experiment.yaml or experiment.<env>.yaml
      # Prompt Flow connections should pre-exist 
      # used automatic (serverless) runtime by default
      # writes the RUN ID in run_id.txt file. Used in next step
      #=====================================
      - name: Execute prompt flow bulk run
        uses: ./.github/actions/execute_script
        with:
          step_name: "Execute prompt flow bulk run"
          script_parameter: |
            python -m llmops.common.prompt_pipeline \
            --subscription_id ${{ env.AZURE_SUBSCRIPTION_ID }} \
            --build_id ${{ github.run_id }} \
            --base_path ${{ inputs.use_case_base_path }} \
            --env_name ${{ inputs.env_name }} \
            --output_file run_id.txt

      #=====================================
      # Reads run_id.txt file. Assigns it to variable RUN_NAME
      # RUN_NAME Used in next step for evaluation of flows
      #=====================================   
      - name: Read PromptFlow Runs
        shell: bash
        run: |
          readarray arr <"run_id.txt"
          run_name=${arr[0]}
          echo $run_name
          echo "RUN_NAME=${run_name}"  >> "$GITHUB_ENV"
          echo $PWD

      #=====================================
      # Registers evaluation dataset in Azure ML as Data Asset
      # Reads appropriate field values from experiment.yaml or experiment.<env>.yaml
      #=====================================
      - name: Register evaluation data asset
        uses: ./.github/actions/execute_script
        with:
          step_name: "Register evaluation data asset"
          script_parameter: |
            python -m llmops.common.register_data_asset \
            --subscription_id ${{ env.AZURE_SUBSCRIPTION_ID }} \
            --base_path ${{ inputs.use_case_base_path }} \
            --env_name ${{ inputs.env_name }}

      #=====================================
      # Executes all Evaluation flows available for a scenario
      # Generates Reports for each RUN as well as consolidated one
      # Uses each RUN ID as input to run evaluation against
      # Loads appropriate evaluation data from Azure ML data asset
      # Reads appropriate field values from experiment.yaml or experiment.<env>.yaml
      # Prompt Flow connections should pre-exist 
      # used automatic (serverless) runtime by default
      #=====================================
      - name: Execute bulk run evaluations
        uses: ./.github/actions/execute_script
        with:
          step_name: "Execute bulk run evaluations"
          script_parameter: |
            python -m llmops.common.prompt_eval \
            --subscription_id ${{ env.AZURE_SUBSCRIPTION_ID }} \
            --build_id ${{ github.run_id }} \
            --base_path ${{ inputs.use_case_base_path }} \
            --env_name ${{ inputs.env_name }} \
            --run_id "$RUN_NAME"

      #=====================================
      # Published generated reports in csv and html format
      # Available as pipeline artifacts
      #=====================================
      - name: Archive CSV
        uses: actions/upload-artifact@v3
        with:
          name: evaluation-reports
          path: ./reports

